{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Análise de Texto\r\n",
        "\r\n",
        "O Processamento de Linguagem Natural (PLN) é um ramo da inteligência artificial (IA) que lida com a linguagem escrita e falada. Você pode usar o PLN para criar soluções que extraem o significado semântico de textos e falas ou formulam respostas significativas em linguagem natural.\r\n",
        "\r\n",
        "Os *Serviços Cognitivos* do Microsoft Azure incluem o serviço de *Análise de Texto*, que oferece alguns recursos de PLN prontos para usar, inclusive a identificação de frases-chave no texto e a classificação de textos com base em sentimentos.\r\n",
        "\r\n",
        "![Um robô lendo um notebook](./images/NLP.jpg)\r\n",
        "\r\n",
        "Por exemplo, suponha que a empresa fictícia *Margie’s Travel* incentive os clientes a enviar análises de suas estadias em hotéis. Você pode usar o serviço de Análise de Texto para resumir as análises extraindo frases-chave, determinar quais delas são positivas e quais são negativas ou examinar o texto da análise em busca de menções a entidades conhecidas, como locais ou pessoas.\r\n",
        "\r\n",
        "## Ver documentos de análise\r\n",
        "\r\n",
        "Vamos começar dando uma olhada em algumas análises de hotéis que foram deixadas pelos clientes.\r\n",
        "\r\n",
        "As análises estão em arquivos de texto. Para vê-las, basta executar o código abaixo clicando no botão **Executar célula** (&#9655;) à esquerda."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import os\r\n",
        "\r\n",
        "# Ler as análises da pasta /data/reviews\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\r\n",
        "\r\n",
        "# Criar uma coleção de análises com propriedades de ID (nome do arquivo) e texto (conteúdo)\r\n",
        "reviews = []\r\n",
        "for file_name in os.listdir(reviews_folder):\r\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\r\n",
        "    review = {\"id\": file_name, \"text\": review_text}\r\n",
        "    reviews.append(review)\r\n",
        "\r\n",
        "for review_num in range(len(reviews)):\r\n",
        "    # print the review text\r\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review1.txt\n",
            "Good Hotel and staff\n",
            "The Royal Hotel, London, UK\n",
            "3/2/2018\n",
            "Clean rooms, good service, great location near Buckingham Palace and Westminster Abbey, and so on. We thoroughly enjoyed our stay. The courtyard is very peaceful and we went to a restaurant which is part of the same group and is Indian ( West coast so plenty of fish) with a Michelin Star. We had the taster menu which was fabulous. The rooms were very well appointed with a kitchen, lounge, bedroom and enormous bathroom. Thoroughly recommended.\n",
            "\n",
            "review2.txt\n",
            "Tired hotel with poor service\n",
            "The Royal Hotel, London, United Kingdom\n",
            "5/6/2018\n",
            "This is a old hotel (has been around since 1950's) and the room furnishings are average - becoming a bit old now and require changing. The internet didn't work and had to come to one of their office rooms to check in for my flight home. The website says it's close to the British Museum, but it's too far to walk.\n",
            "\n",
            "review3.txt\n",
            "Good location and helpful staff, but on a busy road.\n",
            "The Lombard Hotel, San Francisco, USA\n",
            "8/16/2018\n",
            "We stayed here in August after reading reviews. We were very pleased with location, just behind Chestnut Street, a cosmopolitan and trendy area with plenty of restaurants to choose from. The\n",
            "Marina district was lovely to wander through, very interesting houses. Make sure to walk to the San Francisco Museum of Fine Arts and the Marina to get a good view of Golden Gate bridge and the city. On a bus route and easy to get into centre. Rooms were clean with plenty of room and staff were friendly and helpful. The only down side was the noise from Lombard Street so ask to have a room furthest away from traffic noise.\n",
            "\n",
            "review4.txt\n",
            "Very noisy and rooms are tiny\n",
            "The Lombard Hotel, San Francisco, USA\n",
            "9/5/2018\n",
            "Hotel is located on Lombard street which is a very busy SIX lane street directly off the Golden Gate Bridge. Traffic from early morning until late at night especially on weekends. Noise would not be so bad if rooms were better insulated but they are not. Had to put cotton balls in my ears to be able to sleep--was too tired to enjoy the city the next day. Rooms are TINY. I picked the room because it had two queen size beds--but the room barely had space to fit them. With family of four in the room it was tight. With all that said, rooms are clean and they've made an effort to update them. The hotel is in Marina district with lots of good places to eat, within walking distance to Presidio. May be good hotel for young stay-up-late adults on a budget\n",
            "\n",
            "\n"
          ]
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criar um recurso dos Serviços Cognitivos\r\n",
        "\r\n",
        "Para examinar o texto dessas análises, use o serviço cognitivo de **Análise de Texto**. Para isso, é preciso provisionar um recurso de **Análise de Texto** ou **Serviços Cognitivos** na sua assinatura do Azure. (Use um recurso de Análise de Texto se esse for o único serviço que você pretende usar ou se quiser acompanhar a utilização separadamente. Caso contrário, poderá usar um recurso dos Serviços Cognitivos para combinar o serviço de Análise de Texto com outros serviços cognitivos, o que permite que os desenvolvedores usem um único ponto de extremidade e chave para acessá-los).\r\n",
        "\r\n",
        "Caso você ainda não tenha um, use as etapas a seguir para criar um recurso dos **Serviços Cognitivos** na sua assinatura do Azure:\r\n",
        "\r\n",
        "> **Observação**: Se você já tiver um recurso dos Serviços Cognitivos, abra a página de **Início Rápido** no portal do Azure e copie a respectiva chave e o ponto de extremidade para a célula abaixo. Caso contrário, siga as etapas abaixo para criar um.\r\n",
        "\r\n",
        "1. Em outra guia do navegador, abra o portal do Azure em https://portal.azure.com, entrando com sua conta Microsoft.\r\n",
        "2. Clique no botão **&#65291;Criar um recurso**, procure *Serviços Cognitivos* e crie um recurso dos **Serviços Cognitivos** com as configurações abaixo:\r\n",
        "    - **Assinatura**: *sua assinatura do Azure*.\r\n",
        "    - **Grupo de recursos**: *Selecione ou crie um grupo de recursos com um nome exclusivo*.\r\n",
        "    - **Região**: *Escolha qualquer região disponível*:\r\n",
        "    - **Nome**: *Insira um nome exclusivo*.\r\n",
        "    - **Tipo de preço**: S0\r\n",
        "    - **Confirmo que li e entendi os avisos**: Selecionado.\r\n",
        "3. Aguarde até que a implantação seja concluída. Depois, entre em seu recurso dos Serviços Cognitivos e, na página **Visão geral**, clique no link para gerenciar as chaves do serviço. Você precisará do ponto de extremidade e das chaves para se conectar aos seus recursos dos Serviços Cognitivos em aplicativos clientes.\r\n",
        "\r\n",
        "### Obter a chave e o ponto de extremidade do seu recurso dos Serviços Cognitivos\r\n",
        "\r\n",
        "Para usar seu recurso dos Serviços Cognitivos, os aplicativos clientes precisam do ponto de extremidade e da chave de autenticação:\r\n",
        "\r\n",
        "1. No portal do Azure, na página **Chaves e ponto de extremidade** do seu recurso dos Serviços Cognitivos, copie a **Chave 1** do recurso e cole no código abaixo, substituindo **YOUR_COG_KEY**.\r\n",
        "2. Copie o **ponto de extremidade** do recurso e cole no código abaixo, substituindo **YOUR_COG_ENDPOINT**.\r\n",
        "3. Execute o código da célula abaixo clicando no botão verde <span style=\"color:green\">&#9655;</span>."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cog_key = 'e09c79f3eeb54c2894df8b52f297e8f2'\r\n",
        "cog_endpoint = 'https://cs-hsouza-01.cognitiveservices.azure.com/'\r\n",
        "\r\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detectar idioma\r\n",
        "Vamos começar identificando o idioma em que essas análises foram escritas."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import os\r\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\r\n",
        "from msrest.authentication import CognitiveServicesCredentials\r\n",
        "\r\n",
        "# Obter um cliente para seu recurso do serviço cognitivo de Análise de Texto\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\r\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\r\n",
        "\r\n",
        "# Examinar as análises que você leu na pasta /data/reviews anteriormente\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\r\n",
        "\r\n",
        "# imprimir detalhes da linguagem detectada em cada análise\r\n",
        "for review_num in range(len(reviews)):\r\n",
        "    # print the review id\r\n",
        "    print(reviews[review_num]['id'])\r\n",
        "\r\n",
        "    # Get the language details for this review\r\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\r\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\r\n",
        "\r\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\r\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extrair frases-chave\r\n",
        "\r\n",
        "Agora você já pode examinar o texto das análises dos clientes para identificar frases-chave que indicam os principais pontos discutidos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# # Usar os clientes e as análises criadas na célula de código anterior para extrair frases-chave\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\r\n",
        "\r\n",
        "# imprimir frases-chave de cada análise\r\n",
        "for review_num in range(len(reviews)):\r\n",
        "    # print the review id\r\n",
        "    print(reviews[review_num]['id'])\r\n",
        "\r\n",
        "    # Get the key phrases in this review\r\n",
        "    print('\\nKey Phrases:')\r\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\r\n",
        "    # Print each key phrase\r\n",
        "    for key_phrase in key_phrases:\r\n",
        "        print('\\t', key_phrase)\r\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As frases-chave podem ajudar você a entender os principais pontos de discussão de cada análise. Por exemplo, uma análise que contenha a frase \"equipe prestativa\" ou \"atendimento ruim\" pode dar pistas sobre algumas das principais preocupações do avaliador.\r\n",
        "\r\n",
        "## Determinar o sentimento\r\n",
        "\r\n",
        "Talvez seja útil classificar as análises como *positivas* ou *negativas* de acordo com uma *pontuação de sentimento*. De novo, você pode usar o serviço de Análise de Texto para isso."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Usar os clientes e as análises que você criou anteriormente para obter pontuações de sentimento\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\r\n",
        "\r\n",
        "# Imprimir os resultados de cada análise\r\n",
        "for review_num in range(len(reviews)):\r\n",
        "\r\n",
        "    # Get the sentiment score for this review\r\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\r\n",
        "\r\n",
        "    # classifiy 'positive' if more than 0.5, \r\n",
        "    if sentiment_score < 0.5:\r\n",
        "        sentiment = 'negative'\r\n",
        "    else:\r\n",
        "        sentiment = 'positive'\r\n",
        "\r\n",
        "    # print file name and sentiment\r\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extrair entidades conhecidas\r\n",
        "\r\n",
        "*Entidades* são coisas que podem ser mencionadas no texto e fazem referência a algum tipo de item de compreensão comum. Por exemplo, um local, uma pessoa ou uma data. Vamos supor que você esteja interessado em datas e locais mencionados nas análises. Você poderá usar o código abaixo para identificá-los."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Usar os clientes e as análises que você criou anteriormente para obter entidades nomeadas\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Imprimir os resultados de cada análise\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only get location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que algumas entidades são conhecidas o bastante para ter uma página da Wikipedia associada a elas. Nesses casos, o serviço de Análise de Texto retorna o URL dessa página.\r\n",
        "\r\n",
        "## Saiba mais\r\n",
        "\r\n",
        "Para mais informações sobre o serviço de Análise de Texto, consulte a [documentação do serviço](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "interpreter": {
      "hash": "5b4e01f77ac178ff0eeb38c81be30feb99ea5d42ef23128eeb3095913a50c664"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}